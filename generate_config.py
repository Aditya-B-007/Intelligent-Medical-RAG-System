import mysql.connector
import json
import os
import re
import time
from typing import List, Dict, Any, Optional
import google.generativeai as genai
import logging
import uuid
from Config import AppConfig
logger = logging.getLogger("GenerateConfig") #This is for outputting any errors that can take place in the running of the python file.
genai.configure(api_key=AppConfig.GEMINI_API_KEY)
GEMINI_MODEL_NAME = os.getenv("GEMINI_SCHEMA_MODEL", "gemini-1.5-flash")
#The whole purpose of the below function is for connecting to a database and make the connection.
def get_db_connection(config: Dict[str, Any], retries: int = 2, delay: float = 1.0) -> Optional[mysql.connector.MySQLConnection]:
    allowed_keys = {"host", "port", "user", "password", "database"}
    db_config = {key: value for key, value in config.items() if key in allowed_keys}
    for attempt in range(retries):
        try:
            return mysql.connector.connect(**db_config)
        except mysql.connector.Error as e:
            logger.warning(f"[{config.get('database')}] DB connection failed (attempt {attempt + 1}): {e}")
            time.sleep(delay)
    return None
#The purpose of the below function is to extrat the complete schema from the table.
def get_full_schema(cursor, db_name: str) -> Optional[Dict[str, List[str]]]:
    schema = {}
    try:
        cursor.execute("SHOW TABLES")#A DB cursor object
        tables = [table[0] for table in cursor.fetchall()]
        for table in tables:
            cursor.execute(f"DESCRIBE `{table}`")
            desc = cursor.fetchall()
            columns = [{"Field": row[0], "Type": row[1], "Key": row[3]} for row in desc]
            schema[table] = columns
        return schema #This is a dictionary where, the keys are table names and values are lists of column dictionaries
    except mysql.connector.Error as e:
        logger.error(f"Could not extract schema from {db_name}: {e}")
        return None
#The below function is for verification purpose to check if the mapping schema generated by the LLM is authentic or not.
def validate_schema(schema_mapping: Dict[str, Any], schema: Dict[str, List[str]]) -> bool:
    table = schema_mapping.get("table")
    columns = schema_mapping.get("columns", {})
    if not table or table not in schema:
        logger.error(f"Invalid table '{table}' not found in DB schema.")
        return False
    actual_cols=[col['Field'] for col in schema[table]]
    for logical_key in ["patient_id", "patient_name", "patient_dob"]:
        mapped_col = columns.get(logical_key)
        if mapped_col not in actual_cols:
            logger.error(
                f"Invalid schema: Mapped '{logical_key}' â†’ '{mapped_col}' does not exist in actual columns of '{table}'."
            )
            return False

    return True
#This sends the database schema to the gemini model and then prompts it to identify the patient table and the need columns. Then output is of JSON format.
def get_schema_from_gemini(db_schema: Dict[str, List[str]], db_name: str) -> Optional[Dict[str, Any]]:
    prompt = f"""
You are a hospital database analyst. Below is the schema of a hospital database '{db_name}'.
Each table maps to a list of column descriptors.

Each column contains:
- Field: the name of the column
- Type: the data type
- Key: primary or foreign key status

Analyze this schema to identify:
1. The most likely patient table
2. The patient identifier column (e.g., id, mrn)
3. The column containing the patient name
4. The column containing the date of birth

Schema:
{json.dumps(db_schema, indent=2)}

Respond ONLY with a JSON in this format:
{{
  "table": "table_name",
  "columns": {{
    "patient_id": "column_name",
    "patient_name": "column_name",
    "patient_dob": "column_name"
  }}
}}
"""
    try:
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(prompt)
        raw_text = response.text
        match = re.search(r'{.*}', raw_text, re.DOTALL)
        if match:
            parsed = json.loads(match.group(0))
            return parsed
        else:
            logger.error(f"Gemini did not return valid JSON:\n{raw_text}")
    except Exception as e:
        logger.error(f"Gemini API error for '{db_name}': {e}")
    return None
#This is the orchastrating function meant for calling the above functions I have defined.
def discover_data_sources(db_sources: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    discovered_sources = [] #This is a list that accumulates the processed configuration dictionaries for each successfully analyzed database source.
    for config in db_sources: #db_sources is a list of dictionaries where each dictionary contains a config for a database.
        db_name = config["database"]
        logger.info(f"Inspecting DB: {db_name}")
        conn = get_db_connection(config)
        if not conn:
            continue

        try:
            cursor = conn.cursor()
            full_schema = get_full_schema(cursor, db_name)
        finally:
            try: cursor.close()
            except: pass
            conn.close()

        if not full_schema:
            continue

        schema_mapping = get_schema_from_gemini(full_schema, db_name)
        if not schema_mapping or not validate_schema(schema_mapping, full_schema):
            logger.warning(f"Schema mapping invalid for {db_name}, skipping.")
            continue

        global_id = str(uuid.uuid4())
        source_config = {
            "source_name": f"{db_name}",
            "config": config,
            "schema_mapping": schema_mapping,
            "global_patient_id": global_id,
            "local_patient_id": None,  # To be resolved dynamically
            "full_schema":full_schema
        }
        discovered_sources.append(source_config)

    return discovered_sources #A list of dictionaries,each representing a discovered and mapped data sources.

def create_mpi_jsonl_file(file_path: str, records: List[Dict[str, Any]]) -> bool:
    try:
        with open(file_path, 'w') as f:
            for rec in records:
                f.write(json.dumps(rec) + '\n')
        logger.info(f"MPI written to '{file_path}' with {len(records)} records.")
        return True
    except Exception as e:
        logger.error(f"Error writing MPI to '{file_path}': {e}")
        return False
#This function is the entry point into the script.
def setup_mpi_config(db_connections: List[Dict[str, Any]], mpi_file_path: str) -> Dict[str, Any]:
    logger.info("Starting MPI config generation via Gemini...")
    discovered = discover_data_sources(db_connections)
    if not discovered:
        logger.error("No valid data sources found.")
        return {}

    if not create_mpi_jsonl_file(mpi_file_path, discovered):
        return {}

    return {
        "data_sources": discovered,
        "mpi_file_path": mpi_file_path
    }